{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "semantic_similarity_chatbot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "txUYirYZ8Jep",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I2cvPJ-98Kyy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unrar e \"/content/gdrive/My Drive/final_cleaned_data.rar\" \"/content\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XYaOlN9zRAn4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sDFEXEfhRMCB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SJRSGP2Q7_Hg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "import numpy as np\n",
        "import spacy\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pPYAyaXIFamG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JizJee4YBAdJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sentence_mean(nlp, s):\n",
        "    if s == \"\":\n",
        "        s = \" \"\n",
        "    doc = nlp(s, disable=['tagger', 'parser'])\n",
        "    return np.mean(np.array([w.vector for w in doc]), axis=0)\n",
        "sentence_mean(nlp, \"This... is a test.\").shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gtNHMpwh8sIL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "responses = {}\n",
        "f = open('final_cleaned_data.json', 'r')\n",
        "te = f.read() \n",
        "responses = json.loads(te)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tb4yS84ZBKUW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences=[]\n",
        "label=[]\n",
        "for x in responses:\n",
        "  sentences.append(x['message'])\n",
        "  label.append(x['response'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tp3EJafbAxm8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_shape = (len(sentences),nlp.vocab.vectors_length)\n",
        "X_train = np.zeros(X_train_shape)\n",
        "# X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F2SLPnNvOv7G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train_shape = (len(responses),nlp.vocab.vectors_length)\n",
        "y_train = np.zeros(y_train_shape)\n",
        "# y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jsiMXNOFCURb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i,sentence in enumerate(sentences[:10000]):\n",
        "   print(i)\n",
        "   X_train[i,:] = nlp(sentence).vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "89DpyjETOsdV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i,response in enumerate(label[:10000]):\n",
        "   print(i)\n",
        "   y_train[i,:] = nlp(response).vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L2-RRPv5ZZIL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "SVC_pipeline = Pipeline([\n",
        "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
        "                ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
        "            ])\n",
        "for category in categories:\n",
        "    print('... Processing {}'.format(category))\n",
        "    # train the model using X_dtm & y\n",
        "    SVC_pipeline.fit(X_train, train[category])\n",
        "    # compute the testing accuracy\n",
        "    prediction = SVC_pipeline.predict(X_test)\n",
        "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "im51OqVEFrSV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "0ae8dcd5-ebc1-4950-f6fc-0c84cb58fd36"
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "X_test_ten_thousands = X_train[:10000, :]\n",
        "y_test_ten_thousands = y_train[:10000, :]\n",
        "\n",
        "size = X_test_ten_thousands.shape[0]\n",
        "per = math.floor((size * 70)/100)\n",
        "\n",
        "X_train_s = X_test_ten_thousands[:per, :]\n",
        "y_train_s = y_test_ten_thousands[:per, :]\n",
        "X_test_s = X_test_ten_thousands[-(size-per):, :]\n",
        "y_test_s = y_test_ten_thousands[-(size-per):, :]\n",
        "\n",
        "print(X_train_s.shape)\n",
        "print(y_train_s.shape)\n",
        "print(X_test_s.shape)\n",
        "print(y_test_s.shape)\n",
        "\n",
        "# y_train_s_list = y_train_s.tolist()\n",
        "# asd = np.array(y_train_s_list)\n",
        "# np.reshape(asd, (7000, 1))\n",
        "# print(asd.shape)\n",
        "# print(len(y_train_s_list))\n",
        "# print(len(y_train_s_list[0]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7000, 300)\n",
            "(7000, 300)\n",
            "(3000, 300)\n",
            "(3000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i7qV_wphSX0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "4ee607d4-eee4-4fe6-f605-f92def9fae23"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC(C=1)\n",
        "clf.fit(X_train_s, y_train_s)\n",
        "print('Accuracy: {}'.format(clf.score(X_test_s, y_test_s)))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-af1a91e8c873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    147\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[1;32m    148\u001b[0m                          \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    759\u001b[0m                         dtype=None)\n\u001b[1;32m    760\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: bad input shape (7000, 300)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ppulERZ5Tz5a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install simpleneighbors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-_sFq49LKISH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The cell below makes a new Simple Neighbors object called `nns` and initializes it with 300 dimensions (the shape of the word vectors in spaCy, and also the shape of our summary vectors). It then samples ten thousand random conversational turns from the Cornell corpus, finds sentence vectors for each of them, and adds them to the database. (The `np.any()` line just checks to make sure that we don't add any vectors that are all zeroes by accidentâ€”this can mess up the nearest-neighbor search.)\n",
        "\n",
        "Notes on the code below:\n",
        "\n",
        "* I decided to just sample ten thousand turns so that the index will build faster. You can change this number to your liking!\n",
        "* It only adds *turns that have responses* to the database (i.e., keys in the `responses` lookup). Because of the way the bot works, we don't need to keep track of the last turn of a conversation, since it (by definition) will have no replies."
      ]
    },
    {
      "metadata": {
        "id": "X8jODdF-BHxR",
        "colab_type": "code",
        "outputId": "12d40d9f-a888-4aa8-a4ef-256e1f3b3fd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "cell_type": "code",
      "source": [
        "from simpleneighbors import SimpleNeighbors\n",
        "\n",
        "nns = SimpleNeighbors(300)\n",
        "for i, line_id in enumerate(random.sample(list(responses.keys()), 10000)):\n",
        "    # show progress\n",
        "    if i % 1000 == 0: print(i, line_id, movie_lines[line_id])\n",
        "    line_text = movie_lines[line_id]\n",
        "    summary_vector = sentence_mean(nlp, line_text)\n",
        "    if np.any(summary_vector):\n",
        "        nns.add_one(line_id, summary_vector)\n",
        "nns.build()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 L147263 You're not helping.\n",
            "1000 L14186 An angel, when she was having one of her headaches.\n",
            "2000 L399703 Nah... scotch.\n",
            "3000 L447170 That COULD BE TOLD.\n",
            "4000 L327382 Why fucking not!  I deserve it.\n",
            "5000 L603751 It's spectacular...\n",
            "6000 L59033 Will you do something for me?\n",
            "7000 L505431 That's a game isn't it?  Anyway...  There's been some interesting developments.\n",
            "8000 L106937 Come on, Pop, all I want to know is one thing.  Just one thing after he made such a big deal out of it.  I bet it wasn't a big deal.  Was it, Caesar?\n",
            "9000 L159864 Don't shoot, man, don't shoot!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4UOeTbDtL8l3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's take it for a spin! The code in the following cell finds the turn most similar to the string in the variable `sentence`. (You can change this string to whatever you want.) It then uses the Simple Neighbors object to find the turn in the database with the most similar vector, and then uses the `responses` lookup to find the *response* to that turn. That response will be our bot's output."
      ]
    },
    {
      "metadata": {
        "id": "l656oBJoBLaa",
        "colab_type": "code",
        "outputId": "e63de4fb-6056-42f7-898b-f6eede2c8480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "sentence = \"I like making bots.\"\n",
        "picked = nns.nearest(sentence_mean(nlp, sentence), 5)[0]\n",
        "response_line_id = responses[picked]\n",
        "\n",
        "print(\"Your line:\\n\\t\", sentence)\n",
        "print(\"Most similar turn:\\n\\t\", movie_lines[picked])\n",
        "print(\"Response to most similar turn:\\n\\t\", movie_lines[response_line_id])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your line:\n",
            "\t I like making bots.\n",
            "Most similar turn:\n",
            "\t I like that.\n",
            "Response to most similar turn:\n",
            "\t I still think we should have met them first.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J2AUaRgVPQco",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Putting it all together\n",
        "\n",
        "The code above is all you need to make a conversational chatbot based on semantic similarity. But there's a lot of stuff to keep track of! So I wrote a little bit of \"glue code\" to make it even easier. You can [see the source code on GitHub](https://github.com/aparrish/semanticsimilaritychatbot/); all the important stuff is [in this file](https://github.com/aparrish/semanticsimilaritychatbot/blob/master/semanticsimilaritychatbot/__init__.py). I'm going to use this library to rewrite the code above in just a few lines, and then we'll use the resulting object to make a chatbot you can use in the browser.\n",
        "\n",
        "First, download and install the library:"
      ]
    },
    {
      "metadata": {
        "id": "TI4sCHjmQFfu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install https://github.com/aparrish/semanticsimilaritychatbot/archive/master.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nPGClLIPQYBw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then create a chatbot object, passing in the spaCy language object (`nlp`) and the number of dimensions:"
      ]
    },
    {
      "metadata": {
        "id": "xWbiYvA-K3xv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from semanticsimilaritychatbot import SemanticSimilarityChatbot\n",
        "chatbot = SemanticSimilarityChatbot(nlp, 300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TvsLgSCKQfIF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The `.add_pair()` method in the object takes two strings: a turn and the response to that turn. We'll get these from the `responses` and `movie_lines` lookups, again sampling ten thousand pairs at random. This cell will take a little while to run:"
      ]
    },
    {
      "metadata": {
        "id": "XaEYCz70KyPg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample_n = 10000\n",
        "for first_id, second_id in random.sample(list(responses.items()), sample_n):\n",
        "    chatbot.add_pair(movie_lines[first_id], movie_lines[second_id])\n",
        "chatbot.build()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FixHpUnoRLdC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once you've built the database, the `.response_for()` method returns a plausible response from the database, based on semantic similarity. Try it out by changing the text between the quotation marks:"
      ]
    },
    {
      "metadata": {
        "id": "B-sTY8OUK1ju",
        "colab_type": "code",
        "outputId": "63534634-5381-4a88-8540-0ecc531eb4bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(chatbot.response_for(\"Hello computer!\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi there!  You alright?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jdEXLwEHMKAh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To add variety, the `.response_for()` method actually selects randomly among several similar turns. You can change the number of turns it chooses from by passing a second parameter (a number) to the method. In general, the higher the number, the greater the chance is that you'll get an unusual result:"
      ]
    },
    {
      "metadata": {
        "id": "gmDFQy-2MiCr",
        "colab_type": "code",
        "outputId": "ae605aa1-c467-4d72-9ad9-bd9557b622e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "cell_type": "code",
      "source": [
        "my_turn = \"The weather's nice today, don't you think?\"\n",
        "for i in range(5, 51, 5):\n",
        "    print(\"picking from\", i, \"possible responses:\")\n",
        "    print(chatbot.response_for(my_turn, i))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "picking from 5 possible responses:\n",
            "Well, I'd like to be lady-like and think it over.\n",
            "\n",
            "picking from 10 possible responses:\n",
            "What is it. Tammy?\n",
            "\n",
            "picking from 15 possible responses:\n",
            "Everybody does?\n",
            "\n",
            "picking from 20 possible responses:\n",
            "What sign?\n",
            "\n",
            "picking from 25 possible responses:\n",
            "I don't know. What do you feel like doing?\n",
            "\n",
            "picking from 30 possible responses:\n",
            "Have you ever considered piracy? You'd make a wonderful Dread Pirate Roberts.\n",
            "\n",
            "picking from 35 possible responses:\n",
            "Ohhh. You're in therapy too, Marty?\n",
            "\n",
            "picking from 40 possible responses:\n",
            "Yeah?\n",
            "\n",
            "picking from 45 possible responses:\n",
            "Kid stuff or not, it doesn't happen every day, I want to heat it - and if you won't say it, you can sing it...\n",
            "\n",
            "picking from 50 possible responses:\n",
            "Right. I promised my mother.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tZw0DgPiRgz4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Semantic Similarity Chatbot object has a `.save()` method that saves the pre-built database to disk, using a filename prefix you supply. (It saves three different files: `<prefix>.annoy`, `<prefix>-data.pkl`, and `<prefix>-chatbot.pkl`)."
      ]
    },
    {
      "metadata": {
        "id": "cPgATDpnLTYv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chatbot.save(\"movielines-10k-sample\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FVM_GcjoR9pG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can use a previously-saved database using the `.load()` class method, like so. (This means you don't have to build the database again: you can just load it and start calling `.response_for()`.)"
      ]
    },
    {
      "metadata": {
        "id": "Wutboh4MLkja",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chatbot = SemanticSimilarityChatbot.load(\"movielines-10k-sample\", nlp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-6IOQ9DPNrOR",
        "colab_type": "code",
        "outputId": "40663413-60d1-45ba-9586-5ccfda5cd659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(chatbot.response_for(\"I'm going to go get some coffee.\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Instant rice...?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7Dp0gmuzSkG_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you're using this notebook on Google Colab, the following cell will download all of the files from the pre-built bot to your computer so you can use them later. (Note that you'll still have to download and install spaCy for the chatbot to work.) If you're running the notebook locally with Jupyter Notebook, the files will end up in the same directory as the notebook file itself."
      ]
    },
    {
      "metadata": {
        "id": "kCeo-cHdSUxg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('movielines-10k-sample.annoy')\n",
        "files.download('movielines-10k-sample-data.pkl')\n",
        "files.download('movielines-10k-sample-chatbot.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M1wElvooTBjp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Making it interactive\n",
        "\n",
        "If you're using this notebook in Google Colab, the following cell will create a little interactive interface for chatting with the bot that you just built. Run the two cells below and start typing into the box."
      ]
    },
    {
      "metadata": {
        "id": "WSjtkXigBuRo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chatbot_html = \"\"\"\n",
        "<style type=\"text/css\">#log p { margin: 5px; font-family: sans-serif; }</style>\n",
        "<div id=\"log\"\n",
        "     style=\"box-sizing: border-box;\n",
        "            width: 600px;\n",
        "            height: 32em;\n",
        "            border: 1px grey solid;\n",
        "            padding: 2px;\n",
        "            overflow: scroll;\">\n",
        "</div>\n",
        "<input type=\"text\" id=\"typehere\" placeholder=\"type here!\"\n",
        "       style=\"box-sizing: border-box;\n",
        "              width: 600px;\n",
        "              margin-top: 5px;\">\n",
        "<script>\n",
        "function paraWithText(t) {\n",
        "    let tn = document.createTextNode(t);\n",
        "    let ptag = document.createElement('p');\n",
        "    ptag.appendChild(tn);\n",
        "    return ptag;\n",
        "}\n",
        "document.querySelector('#typehere').onchange = async function() {\n",
        "    let inputField = document.querySelector('#typehere');\n",
        "    let val = inputField.value;\n",
        "    inputField.value = \"\";\n",
        "    let resp = await getResp(val);\n",
        "    let objDiv = document.getElementById(\"log\");\n",
        "    objDiv.appendChild(paraWithText('ðŸ˜€: ' + val));\n",
        "    objDiv.appendChild(paraWithText('ðŸ¤–: ' + resp));\n",
        "    objDiv.scrollTop = objDiv.scrollHeight;\n",
        "};\n",
        "async function colabGetResp(val) {\n",
        "    let resp = await google.colab.kernel.invokeFunction(\n",
        "        'notebook.get_response', [val], {});\n",
        "    return resp.data['application/json']['result'];\n",
        "}\n",
        "async function webGetResp(val) {\n",
        "    let resp = await fetch(\"/response.json?sentence=\" + \n",
        "        encodeURIComponent(val));\n",
        "    let data = await resp.json();\n",
        "    return data['result'];\n",
        "}\n",
        "</script>\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SHilVz_Yy3Th",
        "colab_type": "code",
        "outputId": "5b29357f-29f4-4450-a827-c3383dd67e66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        }
      },
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.HTML(chatbot_html + \\\n",
        "                             \"<script>let getResp = colabGetResp;</script>\"))\n",
        "\n",
        "def get_response(val):\n",
        "    resp = chatbot.response_for(val)\n",
        "    return IPython.display.JSON({'result': resp})\n",
        "\n",
        "output.register_callback('notebook.get_response', get_response)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style type=\"text/css\">#log p { margin: 5px; font-family: sans-serif; }</style>\n",
              "<div id=\"log\"\n",
              "     style=\"box-sizing: border-box;\n",
              "            width: 600px;\n",
              "            height: 32em;\n",
              "            border: 1px grey solid;\n",
              "            padding: 2px;\n",
              "            overflow: scroll;\">\n",
              "</div>\n",
              "<input type=\"text\" id=\"typehere\" placeholder=\"type here!\"\n",
              "       style=\"box-sizing: border-box;\n",
              "              width: 600px;\n",
              "              margin-top: 5px;\">\n",
              "<script>\n",
              "function paraWithText(t) {\n",
              "    let tn = document.createTextNode(t);\n",
              "    let ptag = document.createElement('p');\n",
              "    ptag.appendChild(tn);\n",
              "    return ptag;\n",
              "}\n",
              "document.querySelector('#typehere').onchange = async function() {\n",
              "    let inputField = document.querySelector('#typehere');\n",
              "    let val = inputField.value;\n",
              "    inputField.value = \"\";\n",
              "    let resp = await getResp(val);\n",
              "    let objDiv = document.getElementById(\"log\");\n",
              "    objDiv.appendChild(paraWithText('ðŸ˜€: ' + val));\n",
              "    objDiv.appendChild(paraWithText('ðŸ¤–: ' + resp));\n",
              "    objDiv.scrollTop = objDiv.scrollHeight;\n",
              "};\n",
              "async function colabGetResp(val) {\n",
              "    let resp = await google.colab.kernel.invokeFunction(\n",
              "        'notebook.get_response', [val], {});\n",
              "    return resp.data['application/json']['result'];\n",
              "}\n",
              "async function webGetResp(val) {\n",
              "    let resp = await fetch(\"/response.json?sentence=\" + \n",
              "        encodeURIComponent(val));\n",
              "    let data = await resp.json();\n",
              "    return data['result'];\n",
              "}\n",
              "</script>\n",
              "<script>let getResp = colabGetResp;</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Z1CJg2lG67KB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you're not using Colab, try the following two cells to install [Flask](http://flask.pocoo.org) and run a little web server from your notebook that lets you chat with the bot. Click on the link that appears below the second cell to open up the chat in a new window."
      ]
    },
    {
      "metadata": {
        "id": "a4hcd0wU4jGK",
        "colab_type": "code",
        "outputId": "499f750c-7cd6-4496-a191-db60b0016672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install flask"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/e7/08578774ed4536d3242b14dacb4696386634607af824ea997202cd0edb4b/Flask-1.0.2-py2.py3-none-any.whl (91kB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 4.1MB/s \n",
            "\u001b[?25hCollecting click>=5.1 (from flask)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/c1/8806f99713ddb993c5366c362b2f908f18269f8d792aff1abfd700775a77/click-6.7-py2.py3-none-any.whl (71kB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from flask) (0.14.1)\n",
            "Collecting itsdangerous>=0.24 (from flask)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/b4/a60bcdba945c00f6d608d8975131ab3f25b22f2bcfe1dab221165194b2d4/itsdangerous-0.24.tar.gz (46kB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 13.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from flask) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->flask) (1.0)\n",
            "Building wheels for collected packages: itsdangerous\n",
            "  Running setup.py bdist_wheel for itsdangerous ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/2c/4a/61/5599631c1554768c6290b08c02c72d7317910374ca602ff1e5\n",
            "Successfully built itsdangerous\n",
            "Installing collected packages: click, itsdangerous, flask\n",
            "Successfully installed click-6.7 flask-1.0.2 itsdangerous-0.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "25bjOkzX4dC-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "app = Flask(__name__)\n",
        "@app.route(\"/response.json\")\n",
        "def response():\n",
        "    sentence = request.args['sentence']\n",
        "    return jsonify(\n",
        "        {'result': chatbot.response_for(sentence)})\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return chatbot_html + \"<script>let getResp = webGetResp;</script>\"\n",
        "app.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iH-If5m07h8_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Some things to try\n",
        "\n",
        "If you enjoyed following along, here are some things to try:\n",
        "\n",
        "* Use the metadata file that comes with the Cornell corpus to make a chatbot that only uses lines from a particular genre of movie. (How is a comedy chatbot different from an action chatbot?)\n",
        "* Use a different corpus of conversation altogether. Your own chat logs? Conversational exchanges from a novel? Transcripts of interviews on news programs?\n",
        "* Incorporate some context from the conversation when vectorizing the turns. (You might, for example, include the average of not just the given turn but also the turn that preceded it.)"
      ]
    }
  ]
}